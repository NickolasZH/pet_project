{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NickolosZH/pet_project/blob/main/notebook.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xfbIj9jwnVqg"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import torch, torchvision, pathlib, time, os, glob\n",
        "from torch.utils.data import DataLoader, Dataset, Subset\n",
        "from torchvision import transforms\n",
        "from torchsummary import summary\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from collections import defaultdict\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "from google.colab import drive\n",
        "from PIL import Image\n",
        "\n",
        "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fDq7vZgKprqq",
        "outputId": "51d08488-6e9e-41d4-9a77-39acd2dbad7d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "## Гиперпараметры\n",
        "# Путь к папке\n",
        "drive.mount('/content/drive')\n",
        "input_dir = '/content/drive/MyDrive/Colab/Colorectal Cancer/PNG'\n",
        "\n",
        "# Кол-во потоков для DataLoader\n",
        "NUM_WORKERS = 2\n",
        "\n",
        "# Размер изображения\n",
        "SIZE_H = SIZE_W = 150\n",
        "\n",
        "# Кол-во классов датасета\n",
        "NUM_CLASSES = 8\n",
        "\n",
        "# Кол-во эпох\n",
        "EPOCH_NUM = 30\n",
        "\n",
        "# Batch_size\n",
        "BATCH_SIZE = 256\n",
        "\n",
        "# Размер тестовой выборки\n",
        "VAL_SIZE = 0.25\n",
        "\n",
        "# Среднее и стандартное отклонение каналов изображения для нормализации\n",
        "image_mean = [0.485, 0.456, 0.406]\n",
        "image_std = [0.229, 0.224, 0.225]\n",
        "\n",
        "# Last layer (embeddings) size for CNN models\n",
        "EMBEDDING_SIZE = 128"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b8pLF2VTn0B8"
      },
      "outputs": [],
      "source": [
        "# Определим трансформер для предобработки изображений перед созданием датасета\n",
        "transformer = transforms.Compose([\n",
        "    transforms.Resize((SIZE_H, SIZE_W)),  # Подгоняем изображения под фиксированный размер\n",
        "    transforms.ToTensor(),  # Конвертируем в тензоры\n",
        "    transforms.Normalize(image_mean, image_std)  # Нормализуем по каналам\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hl-aHmXw0nTJ"
      },
      "outputs": [],
      "source": [
        "# Получим номера категорий\n",
        "classes = os.listdir(input_dir)\n",
        "int_labels = [int(item[:2]) for item in classes]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sj00KWGJ86vx"
      },
      "outputs": [],
      "source": [
        "# Получим размер датасета\n",
        "data_len = sum([len(files) for r, d, files in os.walk(input_dir)])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g2x-t15_H878"
      },
      "outputs": [],
      "source": [
        "all_images = []\n",
        "for address, dirs, files in os.walk(input_dir):\n",
        "    for name in files:\n",
        "        all_images.append(os.path.join(address, name))\n",
        "\n",
        "# all_images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_c5ZoSV6yJf3"
      },
      "outputs": [],
      "source": [
        "# Функция-помощник для отображения изображений\n",
        "def show_img(cat, image_idx):\n",
        "    \"\"\" Показывает изображение выбранной категории по индексу \"\"\"\n",
        "\n",
        "    path = input_dir + '/' + labels[cat] + '/'\n",
        "    name = os.listdir(path)[image_idx]  # Имя файла\n",
        "    \n",
        "    image = Image.open(path + name)\n",
        "\n",
        "    return Image.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c0JZzLP1a2v7",
        "outputId": "159e24ae-4fcc-4c68-cf9f-33bdc2dd24c4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<bound method Image.getpalette of <PIL.Image.Image image mode=RGB size=150x150 at 0x7F5467AB0F10>>"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ],
      "source": [
        "img = Image.open(all_images[1]).convert('RGB')\n",
        "img.getpalette  \n",
        "# transformer(img)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1f7vihPmwbtY"
      },
      "outputs": [],
      "source": [
        "# Создаём класс датасета\n",
        "class Dataset_CR(Dataset):\n",
        "  \"\"\" Датасет изображений колоректального рака \"\"\"\n",
        "\n",
        "  def __init__(self, names = all_images, root_dir=input_dir, labels=int_labels, transform=None):\n",
        "    \"\"\"\n",
        "    Аргументы:\n",
        "      root_dir (string): Директория со всеми изображениями\n",
        "      labels (list): Номера категорий\n",
        "      transform (callable, optional): Опциональные преобразования над \n",
        "          изображениями\n",
        "    \"\"\"\n",
        "    self.names = all_images\n",
        "    self.root_dir = root_dir\n",
        "    self.labels = labels\n",
        "    self.transform = transform\n",
        "\n",
        "  # Получаем длину датасета\n",
        "  def __len__(self):\n",
        "    return data_len\n",
        "\n",
        "  # Получаем тензор изображения\n",
        "  def __getitem__(self, index):\n",
        "    ID = self.names[index]\n",
        "    image = Image.open(ID).convert('RGB')\n",
        "\n",
        "    # Проверка на трансформации\n",
        "    if self.transform:\n",
        "        image = self.transform(image)\n",
        "    \n",
        "    x_train = image  # Изображение\n",
        "    y_train = int(ID.split('/')[-2][:2])  # Номер категории\n",
        "    \n",
        "    return x_train, y_train\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u8x3FqbsW1yh"
      },
      "outputs": [],
      "source": [
        "# Создаём экземпляр класса Датасет\n",
        "full_dataset = Dataset_CR(names=all_images, \n",
        "                          root_dir=input_dir, \n",
        "                          labels=int_labels, \n",
        "                          transform=transformer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XK_GQY6_YAan",
        "outputId": "d4335b68-499c-4de9-a44f-6b2b2a8fafd0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5000"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ],
      "source": [
        "len(full_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FH17y0PWXwsf"
      },
      "outputs": [],
      "source": [
        "def subset_ind(dataset, ratio: float):\n",
        "  \"\"\" \n",
        "  Функция для получения индексов датасета \n",
        "    (для разделения на обучающую и\n",
        "    тестовую выборки)\n",
        "  \"\"\"\n",
        "\n",
        "  return np.random.choice(len(dataset), size=int(ratio*len(dataset)), replace=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WYy4n-krXTx5"
      },
      "outputs": [],
      "source": [
        "# Получаем тестовой выборки\n",
        "val_idxs = subset_ind(full_dataset, VAL_SIZE)  \n",
        "\n",
        "# Для обучающей выборки берём индексы, которые не вошли в тестовые\n",
        "train_dataset = Subset(full_dataset, [i for i in range(len(full_dataset)) if i not in val_idxs])\n",
        "\n",
        "# Для тестовой выборки берём тестовые индексы\n",
        "val_dataset = Subset(full_dataset, val_idxs)  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1HbvhjNtabCB"
      },
      "outputs": [],
      "source": [
        "# Получаем размер выборок\n",
        "n_train, n_val = len(train_dataset), len(val_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "deKzzlxpaFYg"
      },
      "outputs": [],
      "source": [
        "# Создаём DataLoaders\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=NUM_WORKERS)\n",
        "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=NUM_WORKERS)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CLb31LIZaXra",
        "outputId": "2bf254f8-578c-4182-b299-7b86a1a3f6bc"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([256, 3, 150, 150])"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ],
      "source": [
        "train_iter = iter(train_loader)\n",
        "\n",
        "images, labels = next(train_iter)\n",
        "\n",
        "images.size()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vaUi0J3ui591"
      },
      "outputs": [],
      "source": [
        "# plt.figure(figsize=(14,7))\n",
        "# plt.imshow(images[1, 0], cmap='gray')\n",
        "# plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XGUk1PEzqGEe"
      },
      "outputs": [],
      "source": [
        "def images_from_batch_gen(batch_gen):\n",
        "  \"\"\"\n",
        "  Функция выводит несколько изображений из DataLoaders\n",
        "  \"\"\"\n",
        "\n",
        "  data_batch, label_batch = next(iter(batch_gen))\n",
        "  grid_size = (3, 3)\n",
        "  f, axarr = plt.subplots(*grid_size)\n",
        "  f.set_size_inches(15, 10)\n",
        "  class_names = labels\n",
        "\n",
        "  for i in range(grid_size[0] * grid_size[1]):\n",
        "\n",
        "    # Читаем изображения из batch и меняем оси [H, W, C] -> [H, W, C]\n",
        "    batch_image_ndarray = np.transpose(data_batch[i].numpy(), [1, 2, 0])\n",
        "    # batch_image_ndarray = data_batch[i].numpy()\n",
        "\n",
        "    # Инвертируем нормализацию\n",
        "    src = np.clip(image_std * batch_image_ndarray + image_mean, 0, 1)\n",
        "\n",
        "    # Отображаем сэмплы с подписями\n",
        "    sample_title = 'Label = %d (%s)' % (label_batch[i], class_names[label_batch[i]])\n",
        "    axarr[i // grid_size[0], i % grid_size[0]].imshow(src)\n",
        "    axarr[i // grid_size[0], i % grid_size[0]].set_title(sample_title)\n",
        "  pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fSNXyL4DsdlQ"
      },
      "outputs": [],
      "source": [
        "# images_from_batch_gen(train_loader)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XaEkQy3Cjijw"
      },
      "source": [
        "# Архитектура модели"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z69-bshsjg9B"
      },
      "outputs": [],
      "source": [
        "# class CNN(nn.Module):\n",
        "#     def __init__(self):\n",
        "#         super(CNN, self).__init__() # Наследуем все свойсвтва у nn.Module\n",
        "#         self.layer1 = nn.Sequential(\n",
        "#             nn.Conv2d(in_channels=3, out_channels=9, kernel_size=5, padding=2),\n",
        "#             nn.BatchNorm2d(9),\n",
        "#             nn.ReLU(),\n",
        "#             nn.MaxPool2d(2)\n",
        "#         )\n",
        "\n",
        "#         self.layer2 = nn.Sequential(\n",
        "#             nn.Conv2d(9, 27, kernel_size=5, padding=2),\n",
        "#             nn.BatchNorm2d(27),\n",
        "#             nn.ReLU(),\n",
        "#             nn.MaxPool2d(2)\n",
        "#         )\n",
        "\n",
        "#         self.fc = nn.Linear(in_features=27*37*37, out_features=NUM_CLASSES)\n",
        "\n",
        "#     def forward(self, x):\n",
        "#         out = self.layer1(x)\n",
        "#         out = self.layer2(out)\n",
        "#         out = out.view(out.size(0), -1)\n",
        "#         out = self.fc(out)\n",
        "\n",
        "#         return out\n",
        "\n",
        "# model = CNN().to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "53OtXJV6nRaq"
      },
      "outputs": [],
      "source": [
        "# summary(model, (3, SIZE_H, SIZE_W))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pCWoUlTArzf4"
      },
      "outputs": [],
      "source": [
        "# criterion = nn.CrossEntropyLoss()  \n",
        "# optimizer = torch.optim.Adam(model.parameters(), lr=3e-4)  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-vpcf9awsmgY"
      },
      "outputs": [],
      "source": [
        "# # Обучение модели\n",
        "# history = []\n",
        "# curTime = time.time()\n",
        "# for epoch in range(EPOCH_NUM):\n",
        "#     for i, (images, labels) in enumerate(train_loader):   \n",
        "#         images = images.to(device)\n",
        "#         labels = labels.to(device)\n",
        "#         optimizer.zero_grad()\n",
        "#         outputs = model(images)\n",
        "#         loss = criterion(outputs, labels-1)\n",
        "#         loss.backward()\n",
        "#         history.append(loss)\n",
        "#         optimizer.step()             \n",
        "\n",
        "#     print('Эпоха: [%d/%d], Ошибка: %.4f' \n",
        "#            % (epoch+1, EPOCH_NUM, loss))    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4OgSSXofAOcE"
      },
      "outputs": [],
      "source": [
        "# %%timeit -r 1\n",
        "# # Проверка результатов\n",
        "# model.eval()  # включаем режим проверки\n",
        "\n",
        "# model.to(device)\n",
        "\n",
        "# correct = 0\n",
        "# total = 0\n",
        " \n",
        "# for images, labels in val_loader:\n",
        "#     images = images.to(device)\n",
        "#     labels = labels.to(device)\n",
        "#     outputs = model(images)\n",
        "#     _, predicted = torch.max(outputs.data, 1)\n",
        "#     total += labels.size(0)\n",
        "#     correct += (predicted == labels).sum()\n",
        "    \n",
        "# print('Точность для 5000 картинок: %d %%' % (100 * correct // total))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IrUylLDjn-Qp"
      },
      "source": [
        "# Шаблон конструктора"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_8orgL_odkSt"
      },
      "outputs": [],
      "source": [
        "from IPython.display import clear_output\n",
        "\n",
        "class Runner():\n",
        "    \"\"\"Runner for experiments with supervised model.\"\"\"\n",
        "    def __init__(self, model, opt, device, checkpoint_name=None):\n",
        "        self.model = Даже model\n",
        "        self.opt = opt\n",
        "        self.device = device\n",
        "        self.checkpoint_name = checkpoint_name\n",
        "        \n",
        "        self.epoch = 0\n",
        "        self.output = None\n",
        "        self.metrics = None\n",
        "        self._global_step = 0\n",
        "        self._set_events()\n",
        "        self._top_val_accuracy = -1\n",
        "        self.log_dict = {\n",
        "            \"train\": [],\n",
        "            \"val\": [],\n",
        "            \"test\": []\n",
        "        }\n",
        "    \n",
        "    def _set_events(self):\n",
        "        \"\"\"\n",
        "        Additional method to initialize variables, which may store logging and evaluation info.\n",
        "        The implementation below is extremely simple and only provided to help monitor performance.\n",
        "        \"\"\"\n",
        "        self._phase_name = ''\n",
        "        self.events = {\n",
        "            \"train\": defaultdict(list),\n",
        "            \"val\": defaultdict(list),\n",
        "            \"test\": defaultdict(list)\n",
        "        }\n",
        "    \n",
        "    def _reset_events(self, event_name):\n",
        "        self.events[event_name] = defaultdict(list)\n",
        "    \n",
        "    def forward(self, img_batch, **kwargs):\n",
        "        \"\"\"\n",
        "        Forward method for your Runner.\n",
        "        Should not be called directly outside your Runner.\n",
        "        In simple case, this method should only implement your model forward pass.\n",
        "        It should also return the model predictions and/or other meta info.\n",
        "        \n",
        "        Args:\n",
        "            batch (mapping[str, Any]): dictionary with data batches from DataLoader.\n",
        "            **kwargs: additional parameters to pass to the model.\n",
        "        \"\"\"\n",
        "        logits = self.model(img_batch)\n",
        "        output = {\n",
        "            \"logits\": logits,\n",
        "        }\n",
        "        return output\n",
        "    \n",
        "    def run_criterion(self, batch):\n",
        "        \"\"\"\n",
        "        Applies the criterion to the data batch and the model output, saved in self.output.\n",
        "        \n",
        "        Args:\n",
        "            batch (mapping[str, Any]): dictionary with data batches from DataLoader.\n",
        "        \"\"\"\n",
        "        raise NotImplementedError(\"To be implemented\")\n",
        "    \n",
        "    def output_log(self):\n",
        "        \"\"\"\n",
        "        Output log using the statistics collected in self.events[self._phase_name].\n",
        "        Implement this method for logging purposes.\n",
        "        \"\"\"\n",
        "        raise NotImplementedError(\"To be implemented\")\n",
        "    \n",
        "    def _run_batch(self, batch):\n",
        "        \"\"\"\n",
        "        Runs batch of data through the model, performing forward pass.\n",
        "        This implementation performs data passing to necessary device and is adapted to the default pyTorch DataLoader.\n",
        "        \n",
        "        Args:\n",
        "            batch (mapping[str, Any]): dictionary with data batches from DataLoader.\n",
        "        \"\"\"\n",
        "        # split batch tuple into data batch and label batch\n",
        "        X_batch, y_batch = batch  # Делим кортеж бача на data и label\n",
        "\n",
        "        # update the global step in iterations over source data\n",
        "        self._global_step += len(y_batch)  # обновляем глобальный шаг\n",
        "        \n",
        "        # move data to target device\n",
        "        X_batch = X_batch.to(device)  # Переносим data на device\n",
        "        \n",
        "        # run the batch through the model\n",
        "        self.output = self.forward(X_batch)  # Пропускаем батч через модель и сохраняем в output\n",
        "    \n",
        "    def _run_epoch(self, loader, train_phase=True, output_log=False, **kwargs):\n",
        "        \"\"\"\n",
        "        Method that runs one epoch of the training process.\n",
        "        \n",
        "        Args:\n",
        "            loader (DataLoader): data loader to iterate\n",
        "            train_phase (bool): boolean value to determine if this is the training phase.\n",
        "                Changes behavior for dropout, batch normalization, etc.\n",
        "        \"\"\"\n",
        "        # Train phase\n",
        "        # enable or disable dropout / batch_norm training behavior\n",
        "        self.model.train(train_phase)  # Выставляет режим работы модели в фазу трейн или тест\n",
        "        \n",
        "        _phase_description = 'Training' if train_phase else 'Evaluation'\n",
        "        for batch in tqdm(loader, desc=_phase_description, leave=False):  # Достаём батчи из лоадера\n",
        "            \n",
        "            # forward pass through the model using preset device\n",
        "            self._run_batch(batch)  # Запускаем метод _run_batch и пропускаем каждый батч через модель\n",
        "            \n",
        "            # train on batch: compute loss and gradients\n",
        "            with torch.set_grad_enabled(train_phase):  # Если set_grad включён, то\n",
        "                loss = self.run_criterion(batch)  # считаем loss для каждого батча\n",
        "            \n",
        "            # compute backward pass if training phase\n",
        "            # reminder: don't forget the optimizer step and zeroing the grads\n",
        "            if train_phase:  # Если обучающая фаза, то реализуем backprop\n",
        "                loss.backward()  # Считаем градиент по loss\n",
        "                self.opt.step()  # Делаем шаг оптимизатора\n",
        "                self.opt.zero_grad()  # Обнуляем градиенты оптимизатора\n",
        "        \n",
        "        self.log_dict[self._phase_name].append(np.mean(self.events[self._phase_name]['loss']))  # Сохраняем метрики в словарь для логирования\n",
        "        \n",
        "        if output_log:\n",
        "            self.output_log(**kwargs)\n",
        "    \n",
        "    def train(self, train_loader, val_loader, n_epochs, model=None, opt=None, **kwargs):\n",
        "        \"\"\"\n",
        "        Training process method, that runs for n_epochs over train_loader and performs validation using val_loader.\n",
        "        \n",
        "        Args:\n",
        "            train_loader (DataLoader): training set data loader to iterate over\n",
        "            val_loader (DataLoader): validation set data loader to iterate over\n",
        "            n_epochs (int): epoch number to train for\n",
        "            model (Model): torch nn.Module or nested class, that implements the model. Overwrites self.model.\n",
        "            opt (Optimizer): torch optimizer to be used for loss minimization. Overwrites self.opt.\n",
        "            **kwargs: additional parameters to pass to self.validate.\n",
        "\n",
        "            Метод позволяет обновить train или val loader, кол-во эпох, поменять модель или оптимайзер\n",
        "\n",
        "        \"\"\"\n",
        "        self.opt = (opt or self.opt)  # Оптимизатор\n",
        "        self.model = (model or self.model)  # Модель\n",
        "        \n",
        "        for _epoch in range(n_epochs):  # Проходим по циклу n эпох раз\n",
        "            start_time = time.time()\n",
        "            self.epoch += 1\n",
        "            print(f\"epoch {self.epoch:3d}/{n_epochs:3d} started\")  # Вывести время обучения\n",
        "            \n",
        "            # training part\n",
        "            self._set_events()\n",
        "            self._phase_name = 'train'\n",
        "            self._run_epoch(train_loader, train_phase=True)  # Метод для запуска обучения\n",
        "            \n",
        "            print(f\"epoch {self.epoch:3d}/{n_epochs:3d} took {time.time() - start_time:.2f}s\")\n",
        "            \n",
        "            # validation part. Метод проходит по val_loader \n",
        "            self._phase_name = 'val'\n",
        "            self.validate(val_loader, **kwargs)\n",
        "            self.save_checkpoint()  # и сохраняет чек-пойнты\n",
        "    \n",
        "    @torch.no_grad() # we do not need to save gradients during validation\n",
        "    def validate(self, loader, model=None, phase_name='val', **kwargs):\n",
        "        \"\"\"\n",
        "        Validation process method, that estimates the performance of self.model on validation data in loader.\n",
        "        \n",
        "        Args:\n",
        "            loader (DataLoader): validation set data loader to iterate over\n",
        "            model (Model): torch nn.Module or nested class, that implements the model. Overwrites self.model.\n",
        "            opt (Optimizer): torch optimizer to be used for loss minimization. Overwrites self.opt.\n",
        "            **kwargs: additional parameters to pass to self.validate.\n",
        "        \"\"\"\n",
        "        self._phase_name = phase_name\n",
        "        self._reset_events(phase_name)\n",
        "        self._run_epoch(loader, train_phase=False, output_log=True, **kwargs)  # Можно запустить раннер по другому лоадеру\n",
        "        return self.metrics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8gfWp-cHoPwA"
      },
      "source": [
        "# Редактируем шаблон под себя"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W8AOm3mCgN6B"
      },
      "outputs": [],
      "source": [
        "from torch.nn.modules.loss import CrossEntropyLoss\n",
        "from sklearn.metrics import f1_score, accuracy_score\n",
        "\n",
        "class CNNRunner(Runner):\n",
        "    def run_criterion(self, batch):\n",
        "        \"\"\"\n",
        "        Applies the criterion to the data batch and the model output, saved in self.output.\n",
        "        \n",
        "        Args:\n",
        "            batch (mapping[str, Any]): dictionary with data batches from DataLoader.\n",
        "        \"\"\"\n",
        "        X_batch, label_batch = batch\n",
        "        label_batch = label_batch.to(device)\n",
        "        \n",
        "        logit_batch = self.output['logits']\n",
        "        \n",
        "        # compute loss funciton\n",
        "        loss = CrossEntropyLoss()(logit_batch, label_batch)  # Сохраняем loss\n",
        "        \n",
        "        scores = F.softmax(logit_batch, 1).detach().cpu().numpy()[:, 1].tolist()\n",
        "        labels = label_batch.detach().cpu().numpy().ravel().tolist()\n",
        "        \n",
        "        # log some info. Пишем логи\n",
        "        self.events[self._phase_name]['loss'].append(loss.detach().cpu().numpy())\n",
        "        self.events[self._phase_name]['scores'].extend(scores)\n",
        "        self.events[self._phase_name]['labels'].extend(labels)\n",
        "        \n",
        "        return loss\n",
        "    \n",
        "    def save_checkpoint(self):  # Сохраняем наилучший чекпойнт\n",
        "        val_accuracy = self.metrics['accuracy']\n",
        "        # save checkpoint of the best model to disk\n",
        "        if val_accuracy > self._top_val_accuracy and self.checkpoint_name is not None:\n",
        "            self._top_val_accuracy = val_accuracy\n",
        "            torch.save(model, open(self.checkpoint_name, 'wb'))\n",
        "    \n",
        "    def output_log(self, **kwargs):\n",
        "        \"\"\"\n",
        "        Output log using the statistics collected in self.events[self._phase_name].\n",
        "        Let's have a fancy code for classification metrics calculation.\n",
        "        \"\"\"\n",
        "        scores = np.array(self.events[self._phase_name]['scores'])\n",
        "        labels = np.array(self.events[self._phase_name]['labels'])\n",
        "        \n",
        "        assert len(labels) > 0, print('Label list is empty')\n",
        "        assert len(scores) > 0, print('Score list is empty')\n",
        "        assert len(labels) == len(scores), print('Label and score lists are of different size')\n",
        "        \n",
        "        visualize = kwargs.get('visualize', False)\n",
        "        if visualize:\n",
        "            clear_output()\n",
        "        \n",
        "        self.metrics = {\n",
        "            \"loss\": np.mean(self.events[self._phase_name]['loss']),\n",
        "            \"accuracy\": accuracy_score(labels, np.int32(scores > 0.5)),\n",
        "            \"f1\": f1_score(labels, np.int32(scores > 0.5))\n",
        "        }\n",
        "        print(f'{self._phase_name}: ', end='')\n",
        "        print(' | '.join([f'{k}: {v:.4f}' for k, v in self.metrics.items()]))\n",
        "        \n",
        "        self.save_checkpoint() \n",
        "        \n",
        "        if visualize:\n",
        "            # tensorboard for the poor\n",
        "            fig = plt.figure(figsize=(15,5))\n",
        "            ax1 = fig.add_subplot(1,2,1)\n",
        "            ax2 = fig.add_subplot(1,2,2)\n",
        "            \n",
        "            ax1.plot(self.log_dict['train'], color='b', label='train')\n",
        "            ax1.plot(self.log_dict['val'], color='c', label='val')\n",
        "            ax1.legend()\n",
        "            ax1.set_title('Train/val loss.')\n",
        "            \n",
        "            class_0_scores = np.array(scores)[np.array(labels) == 0]\n",
        "            class_1_scores = np.array(scores)[np.array(labels) == 1]\n",
        "            ax2.hist(class_0_scores, bins=50, range=[0,1.01], color='r', alpha=0.7, label='cats')\n",
        "            ax2.hist(class_1_scores, bins=50, range=[0,1.01], color='g', alpha=0.7, label='dogs')\n",
        "            ax2.legend()\n",
        "            ax2.set_title('Validation set score distribution.')\n",
        "            \n",
        "            plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QpKU3E-_3MWH"
      },
      "source": [
        "# Создаём модель"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6HnK84eDz_3K"
      },
      "outputs": [],
      "source": [
        "class ConvNet(nn.Module): \n",
        "    def __init__(self): \n",
        "        super(ConvNet, self).__init__() \n",
        "        self.layer1 = nn.Sequential( \n",
        "            nn.Conv2d(3, 32, kernel_size=5, stride=1, padding=2), \n",
        "            nn.ReLU(), \n",
        "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        ) \n",
        "\n",
        "        self.layer2 = nn.Sequential( \n",
        "            nn.Conv2d(32, 64, kernel_size=5, stride=1, padding=2), \n",
        "            nn.ReLU(), \n",
        "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        ) \n",
        "\n",
        "        self.drop_out = nn.Dropout() \n",
        "        self.fc1 = nn.Linear(64 * 37 * 37, 1000) \n",
        "        self.fc2 = nn.Linear(1000, NUM_CLASSES+1)\n",
        "\n",
        "    def forward(self, x): \n",
        "        out = self.layer1(x) \n",
        "        out = self.layer2(out) \n",
        "        out = out.reshape(out.size(0), -1) \n",
        "        out = self.drop_out(out) \n",
        "        out = self.fc1(out) \n",
        "        out = self.fc2(out) \n",
        "        return out\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PDUTGr_86LkE"
      },
      "outputs": [],
      "source": [
        "model = ConvNet()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "97nEINr5wFTf"
      },
      "outputs": [],
      "source": [
        "opt = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
        "opt.zero_grad()\n",
        "ckpt_name = 'model_base.ckpt'\n",
        "model = model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8IBeL2Ym3eO8",
        "outputId": "83d5018f-31f4-4c12-8834-eaba2651373d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1         [-1, 32, 150, 150]           2,432\n",
            "              ReLU-2         [-1, 32, 150, 150]               0\n",
            "         MaxPool2d-3           [-1, 32, 75, 75]               0\n",
            "            Conv2d-4           [-1, 64, 75, 75]          51,264\n",
            "              ReLU-5           [-1, 64, 75, 75]               0\n",
            "         MaxPool2d-6           [-1, 64, 37, 37]               0\n",
            "           Dropout-7                [-1, 87616]               0\n",
            "            Linear-8                 [-1, 1000]      87,617,000\n",
            "            Linear-9                    [-1, 9]           9,009\n",
            "================================================================\n",
            "Total params: 87,679,705\n",
            "Trainable params: 87,679,705\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.26\n",
            "Forward/backward pass size (MB): 19.20\n",
            "Params size (MB): 334.47\n",
            "Estimated Total Size (MB): 353.93\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "summary(model, (3, SIZE_H, SIZE_W))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J_fixiH8xJdm"
      },
      "source": [
        "# Tensorboard"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XLJWPzCExODJ",
        "outputId": "2ed89bf7-4d50-4871-8a94-9fe50cb91e72"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The tensorboard extension is already loaded. To reload it, use:\n",
            "  %reload_ext tensorboard\n"
          ]
        }
      ],
      "source": [
        "%load_ext tensorboard\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "\n",
        "# default `log_dir` is \"runs\" - we'll be more specific here\n",
        "writer = SummaryWriter('runs/run1')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wexY3DJGxeDU"
      },
      "outputs": [],
      "source": [
        "# helper function to show an image\n",
        "# (used in the `plot_classes_preds` function below)\n",
        "def matplotlib_imshow(img, one_channel=False):\n",
        "    if one_channel:\n",
        "        img = img.mean(dim=0)\n",
        "    img = img / 2 + 0.5     # unnormalize\n",
        "    npimg = img.numpy()\n",
        "    if one_channel:\n",
        "        plt.imshow(npimg, cmap=\"Greys\")\n",
        "    else:\n",
        "        plt.imshow(np.transpose(npimg, (1, 2, 0)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KxY-EnrjxOqt"
      },
      "outputs": [],
      "source": [
        "# # get some random training images\n",
        "# dataiter = iter(train_loader)\n",
        "# images, labels = next(dataiter)\n",
        "\n",
        "# # create grid of images\n",
        "# img_grid = torchvision.utils.make_grid(images)\n",
        "\n",
        "# # show images\n",
        "# matplotlib_imshow(img_grid, one_channel=True)\n",
        "\n",
        "# # write to tensorboard\n",
        "# writer.add_image('four_colorectal_cancer_images', img_grid)\n",
        "\n",
        "# writer.add_graph(model, images)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ARx2UasLzzxp"
      },
      "outputs": [],
      "source": [
        "# helper functions\n",
        "\n",
        "def images_to_probs(net, images):\n",
        "    '''\n",
        "    Generates predictions and corresponding probabilities from a trained\n",
        "    network and a list of images\n",
        "    '''\n",
        "    output = net(images)\n",
        "    # convert output probabilities to predicted class\n",
        "    _, preds_tensor = torch.max(output, 1)\n",
        "    preds = np.squeeze(preds_tensor.numpy())\n",
        "    return preds, [F.softmax(el, dim=0)[i].item() for i, el in zip(preds, output)]\n",
        "\n",
        "\n",
        "def plot_classes_preds(net, images, labels):\n",
        "    '''\n",
        "    Generates matplotlib Figure using a trained network, along with images\n",
        "    and labels from a batch, that shows the network's top prediction along\n",
        "    with its probability, alongside the actual label, coloring this\n",
        "    information based on whether the prediction was correct or not.\n",
        "    Uses the \"images_to_probs\" function.\n",
        "    '''\n",
        "    preds, probs = images_to_probs(net, images)\n",
        "    # plot the images in the batch, along with predicted and true labels\n",
        "    fig = plt.figure(figsize=(12, 48))\n",
        "    for idx in np.arange(4):\n",
        "        ax = fig.add_subplot(1, 4, idx+1, xticks=[], yticks=[])\n",
        "        matplotlib_imshow(images[idx], one_channel=True)\n",
        "        # ax.set_title(\"{0}, {1:.1f}%\\n(label: {2})\".format(\n",
        "        #     classes[preds[idx]],\n",
        "        #     probs[idx] * 100.0,\n",
        "        #     classes[labels[idx]]),\n",
        "        #             color=(\"green\" if preds[idx]==labels[idx].item() else \"red\"))\n",
        "    return fig"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f7zd7BpfevtP"
      },
      "outputs": [],
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "52MKEMZedegP"
      },
      "outputs": [],
      "source": [
        "# running_loss = 0.0\n",
        "# for epoch in range(30):  # loop over the dataset multiple times\n",
        "\n",
        "#     for i, data in enumerate(train_loader, 0):\n",
        "\n",
        "#         # get the inputs; data is a list of [inputs, labels]\n",
        "#         inputs, labels = data\n",
        "\n",
        "#         # zero the parameter gradients\n",
        "#         optimizer.zero_grad()\n",
        "\n",
        "#         # forward + backward + optimize\n",
        "#         outputs = model(inputs)\n",
        "#         loss = criterion(outputs, labels)\n",
        "#         loss.backward()\n",
        "#         optimizer.step()\n",
        "\n",
        "#         running_loss += loss.item()\n",
        "#         # if i % 1000 == 999:    # every 1000 mini-batches...\n",
        "\n",
        "#         # ...log the running loss\n",
        "#         writer.add_scalar('training loss',\n",
        "#                         running_loss / 1000,\n",
        "#                         epoch * len(train_loader) + i)\n",
        "\n",
        "#         # ...log a Matplotlib Figure showing the model's predictions on a\n",
        "#         # random mini-batch\n",
        "#         writer.add_figure('predictions vs. actuals',\n",
        "#                         plot_classes_preds(model, inputs, labels),\n",
        "#                         global_step=epoch * len(train_loader) + i)\n",
        "#         running_loss = 0.0\n",
        "# print('Finished Training')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RT-AT86Hg9B6"
      },
      "outputs": [],
      "source": [
        "# writer.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iqF1OpJ1xoly"
      },
      "outputs": [],
      "source": [
        "# %tensorboard --logdir=runs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xVy8hxdSxD9v"
      },
      "source": [
        "# Обучаем модель"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cdA_Qp01wHVC"
      },
      "outputs": [],
      "source": [
        "runner = CNNRunner(model, opt, device, ckpt_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S32JePq2wIsf"
      },
      "outputs": [],
      "source": [
        "# runner.train(train_loader, val_loader, n_epochs=2, visualize=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.datasets as datasets\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# Задаем параметры нейронной сети\n",
        "num_epochs = 30\n",
        "batch_size = BATCH_SIZE\n",
        "learning_rate = 0.001\n",
        "\n",
        "# Задаем модель нейронной сети на базе ResNet\n",
        "model = torch.hub.load('pytorch/vision:v0.9.0', 'resnet18', pretrained=True)\n",
        "model.to(device)\n",
        "\n",
        "# Заменяем последний слой на выход с 9 классами\n",
        "num_ftrs = model.fc.in_features\n",
        "model.fc = nn.Linear(num_ftrs, 9)\n",
        "model.to(device)\n",
        "\n",
        "# Задаем функцию потерь и оптимизатор\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "# Обучение нейронной сети\n",
        "total_step = len(train_loader)\n",
        "for epoch in range(num_epochs):\n",
        "    for i, (images, labels) in enumerate(train_loader):\n",
        "        # Передача данных на устройство CUDA\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        # Прямой проход\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        \n",
        "        # Обратный проход и оптимизация\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "        if (i+1) % 100 == 0:\n",
        "            print('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}'.format(epoch+1, num_epochs, i+1, total_step, loss.item()))\n",
        "\n",
        "# Оценка модели на тестовых данных\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for images, labels in val_loader:\n",
        "        # Передача данных на устройство CUDA\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "    print('Accuracy of the network on the {} test images: {} %'.format(total, 100 * correct / total))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mCTzrbOySHSt",
        "outputId": "5602f779-a747-4e2f-ddfa-c6802063f441"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using cache found in /root/.cache/torch/hub/pytorch_vision_v0.9.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of the network on the 1250 test images: 90.64 %\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOgbivcahl1hqKGC1ELDZZb",
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}